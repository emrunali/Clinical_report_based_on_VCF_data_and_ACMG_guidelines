{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKQtk90Wx/pv8BAUvA8u3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrunali/Clinical_report_based_on_VCF_data_and_ACMG_guidelines/blob/main/ACMG_compliant_clinical_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Clone InterVar from its github repository**"
      ],
      "metadata": {
        "id": "S0fF5VeS9rAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WGLab/InterVar.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T7G4cqnEeJL",
        "outputId": "9615206b-7c8c-4bfc-b241-01cb82390a1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'InterVar'...\n",
            "remote: Enumerating objects: 697, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 697 (delta 22), reused 34 (delta 16), pack-reused 655\u001b[K\n",
            "Receiving objects: 100% (697/697), 92.83 MiB | 23.65 MiB/s, done.\n",
            "Resolving deltas: 100% (390/390), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Add mim2gene.txt and morbidmap.txt to /content/intervardb**"
      ],
      "metadata": {
        "id": "7LR-S1zGBZ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd InterVar"
      ],
      "metadata": {
        "id": "xn0NkJd1QPsI",
        "outputId": "a885b73e-c49f-4958-a8c3-c19c45b5f1d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/InterVar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/InterVar')"
      ],
      "metadata": {
        "id": "Umlez7KOE615"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Make sure to modify config.ini file in the InterVar folder so that it can access annovar.**"
      ],
      "metadata": {
        "id": "0KvTxEvPzJfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Before running this cell: download annovar from official website and upload it with humandb folder\n",
        "!unzip /content/annovar-20240319T032745Z-001.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujiaGhCEtVHk",
        "outputId": "6dd01e68-9f8d-45d1-fcfc-90e01e6adcc1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/annovar-20240319T032745Z-001.zip\n",
            "  inflating: /content/annovar/coding_change.pl  \n",
            "  inflating: /content/annovar/retrieve_seq_from_fasta.pl  \n",
            "  inflating: /content/annovar/.DS_Store  \n",
            "  inflating: /content/annovar/table_annovar.pl  \n",
            "  inflating: /content/annovar/annotate_variation.pl  \n",
            "  inflating: /content/annovar/convert2annovar.pl  \n",
            "  inflating: /content/annovar/example/example.simple_region  \n",
            "  inflating: /content/annovar/humandb/GRCh37_MT_ensGene.txt  \n",
            "  inflating: /content/annovar/example/ex1.avinput  \n",
            "  inflating: /content/annovar/humandb/annovar_downdb.log  \n",
            "  inflating: /content/annovar/example/example.tab_region  \n",
            "  inflating: /content/annovar/humandb/hg19_example_db_generic.txt  \n",
            "  inflating: /content/annovar/humandb/GRCh37_MT_ensGeneMrna.fa  \n",
            "  inflating: /content/annovar/humandb/hg19_MT_ensGene.txt  \n",
            "  inflating: /content/annovar/humandb/hg19_refGeneVersion.txt  \n",
            "  inflating: /content/annovar/example/gene_xref.txt  \n",
            "  inflating: /content/annovar/variants_reduction.pl  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_cosmic_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_pathway_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/example/grantham.matrix  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_gwas_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_common_snp_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_disease_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_drug_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/example/snplist.txt  \n",
            "  inflating: /content/annovar/example/ex2.vcf  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_snps_dbsnp_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_hgmd_common_snp_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/list  \n",
            "  inflating: /content/annovar/example/README  \n",
            "  inflating: /content/annovar/humandb/hg19_MT_ensGeneMrna.fa  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_chip_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_evs_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_microsatellites_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_omim_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_pgx_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_hgmd_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_tss_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_snps_ensembl_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_hgmd_disease_genes_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_ptms_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_miRNA_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_dnase_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_hgmdimputed_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_transfac_sites_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_cpg_islands_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/genometrax-sample-files-gff/sample_dbnsfp_featuretype_hg19.gff  \n",
            "  inflating: /content/annovar/humandb/hg19_example_db_gff3.txt  \n",
            "  inflating: /content/annovar/humandb/hg19_refGeneWithVer.txt  \n",
            "  inflating: /content/annovar/humandb/hg19_refGene.txt  \n",
            "  inflating: /content/annovar/example/gene_fullxref.txt  \n",
            "  inflating: /content/annovar/humandb/hg19_refGeneMrna.fa  \n",
            "  inflating: /content/annovar/humandb/hg19_refGeneWithVerMrna.fa  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Install PyVCF for parsing VCF files**"
      ],
      "metadata": {
        "id": "fvDxz1am9IDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3-vcf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxVjzGUYFpcw",
        "outputId": "efb8a97d-5338-4133-beda-b8a65bc3fc60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libhts3 libhtscodecs2 python3-pysam\n",
            "The following NEW packages will be installed:\n",
            "  libhts3 libhtscodecs2 python3-pysam python3-vcf\n",
            "0 upgraded, 4 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 2,235 kB of archives.\n",
            "After this operation, 7,089 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhtscodecs2 amd64 1.1.1-3 [53.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhts3 amd64 1.13+ds-2build1 [390 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pysam amd64 0.17.0+ds-2build1 [1,749 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-vcf amd64 0.6.8+git20170215.476169c-8build1 [43.5 kB]\n",
            "Fetched 2,235 kB in 0s (15.7 MB/s)\n",
            "Selecting previously unselected package libhtscodecs2:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../libhtscodecs2_1.1.1-3_amd64.deb ...\n",
            "Unpacking libhtscodecs2:amd64 (1.1.1-3) ...\n",
            "Selecting previously unselected package libhts3:amd64.\n",
            "Preparing to unpack .../libhts3_1.13+ds-2build1_amd64.deb ...\n",
            "Unpacking libhts3:amd64 (1.13+ds-2build1) ...\n",
            "Selecting previously unselected package python3-pysam.\n",
            "Preparing to unpack .../python3-pysam_0.17.0+ds-2build1_amd64.deb ...\n",
            "Unpacking python3-pysam (0.17.0+ds-2build1) ...\n",
            "Selecting previously unselected package python3-vcf.\n",
            "Preparing to unpack .../python3-vcf_0.6.8+git20170215.476169c-8build1_amd64.deb ...\n",
            "Unpacking python3-vcf (0.6.8+git20170215.476169c-8build1) ...\n",
            "Setting up libhtscodecs2:amd64 (1.1.1-3) ...\n",
            "Setting up libhts3:amd64 (1.13+ds-2build1) ...\n",
            "Setting up python3-pysam (0.17.0+ds-2build1) ...\n",
            "Setting up python3-vcf (0.6.8+git20170215.476169c-8build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Unzip VCF file to make it accessible**"
      ],
      "metadata": {
        "id": "QgmNpp_b93QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gzip -dk /content/normal_sample.deepvariant.vcf.gz"
      ],
      "metadata": {
        "id": "rX3ic_679SyV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Filter variant data from the VCF file based on quality, filter status, and variant allele frequency in sample.**"
      ],
      "metadata": {
        "id": "-RAr9l9O-Hq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pysam\n",
        "\n",
        "def filter_vcf(input_vcf_path, output_vcf_path, min_qual=20, min_vaf=0.3):\n",
        "    vcf_in = pysam.VariantFile(input_vcf_path)\n",
        "    vcf_out = pysam.VariantFile(output_vcf_path, 'w', header=vcf_in.header)\n",
        "\n",
        "    for record in vcf_in.fetch():\n",
        "        if record.qual < min_qual or record.filter.keys() != ['PASS']:\n",
        "            continue\n",
        "\n",
        "        vaf_values = [sample.get('VAF', [0])[0] for sample in record.samples.values()]\n",
        "        if all(vaf < min_vaf for vaf in vaf_values):\n",
        "            continue\n",
        "\n",
        "        vcf_out.write(record)\n",
        "\n",
        "    vcf_in.close()\n",
        "    vcf_out.close()\n",
        "\n",
        "filter_vcf('/content/normal_sample.deepvariant.vcf', '/content/filtered_normal_sample.deepvariant.vcf')\n"
      ],
      "metadata": {
        "id": "0srX0NYFup1h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Run Intervar on the filtered VCF file.**"
      ],
      "metadata": {
        "id": "GWBPA2lT-3HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell to allow perl executions of Intervar before running it\n",
        "!chmod +x /content/annovar/*.pl"
      ],
      "metadata": {
        "id": "z8iBwuqd7GYQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/InterVar/Intervar.py \\\n",
        "    --config /content/InterVar/config.ini \\\n",
        "    --input /content/filtered_normal_sample.deepvariant.vcf \\\n",
        "    --output /content/classified_variants \\\n",
        "    --input_type VCF \\\n",
        "    --buildver hg19"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHvp1DPT8gk0",
        "outputId": "b90fa483-7c05-41af-c119-f8309aebb0ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================================================\n",
            "InterVar                                                                       \n",
            "Interpretation of Pathogenic/Benign for variants using python scripts. \n",
            "\n",
            ".####.##....##.########.########.########..##.....##....###....########.\n",
            "..##..###...##....##....##.......##.....##.##.....##...##.##...##.....##\n",
            "..##..####..##....##....##.......##.....##.##.....##..##...##..##.....##\n",
            "..##..##.##.##....##....######...########..##.....##.##.....##.########.\n",
            "..##..##..####....##....##.......##...##....##...##..#########.##...##..\n",
            "..##..##...###....##....##.......##....##....##.##...##.....##.##....##.\n",
            ".####.##....##....##....########.##.....##....###....##.....##.##.....##\n",
            "\n",
            "=============================================================================\n",
            "\n",
            "%prog 2.2.2 20210727\n",
            "Written by Quan LI,leequan@gmail.com. \n",
            "InterVar is free for non-commercial use without warranty.\n",
            "Please contact the authors for commercial use.\n",
            "Copyright (C) 2016 Wang Genomic Lab\n",
            "============================================================================\n",
            "\n",
            "Notice: Your command of InterVar is ['/content/InterVar/Intervar.py', '--config', '/content/InterVar/config.ini', '--input', '/content/filtered_normal_sample.deepvariant.vcf', '--output', '/content/classified_variants', '--input_type', 'VCF', '--buildver', 'hg19']\n",
            "INFO: The options are {'buildver': 'hg19', 'inputfile': '/content/filtered_normal_sample.deepvariant.vcf', 'inputfile_type': 'VCF', 'outfile': '/content/classified_variants', 'database_intervar': 'intervardb', 'lof_genes': 'intervardb/PVS1.LOF.genes.hg19', 'pm1_domain': 'intervardb/PM1_domains_with_benigns.hg19', 'mim2gene': 'intervardb/mim2gene.txt', 'mim_recessive': 'intervardb/mim_recessive.txt', 'mim_domin': 'intervardb/mim_domin.txt', 'mim_adultonset': 'intervardb/mim_adultonset.txt', 'mim_pheno': 'intervardb/mim_pheno.txt', 'mim_orpha': 'intervardb/mim_orpha.txt', 'orpha': 'intervardb/orpha.txt.utf8', 'knowngenecanonical': 'intervardb/knownGeneCanonical.txt.hg19', 'pp2_genes': 'intervardb/PP2.genes.hg19', 'bp1_genes': 'intervardb/BP1.genes.hg19', 'ps1_aa': 'intervardb/PS1.AA.change.patho.hg19', 'ps4_snps': 'intervardb/PS4.variants.hg19', 'bs2_snps': 'intervardb/BS2_hom_het.hg19', 'exclude_snps': 'intervardb/ext.variants.hg19', 'evidence_file': 'None', 'disorder_cutoff': '0.01', 'onetranscript': 'FALSE', 'otherinfo': 'TRUE', 'convert2annovar': '/content/annovar/convert2annovar.pl', 'table_annovar': '/content/annovar/table_annovar.pl', 'annotate_variation': '/content/annovar/annotate_variation.pl', 'database_locat': '/content/annovar/humandb', 'database_names': 'refGene esp6500siv2_all 1000g2015aug avsnp147 dbnsfp42a clinvar_20210501 gnomad_genome dbscsnv11 rmsk ensGene knownGene', 'current_version': 'Intervar_20210727', 'public_dev': 'https://github.com/WGLab/InterVar/releases', 'skip_annovar': False} \n",
            "Warning: the folder of /content/annovar/humandb is already created!\n",
            "Warning: The Annovar dataset file of esp6500siv2_all is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_esp6500siv2_all.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar esp6500siv2_all /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_esp6500siv2_all.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_esp6500siv2_all.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of 1000g2015aug is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_1000g2015aug.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar 1000g2015aug /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_1000g2015aug.zip ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of avsnp147 is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_avsnp147.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar avsnp147 /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_avsnp147.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_avsnp147.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of dbnsfp42a is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_dbnsfp42a.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar dbnsfp42a /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_dbnsfp42a.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_dbnsfp42a.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of clinvar_20210501 is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_clinvar_20210501.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar clinvar_20210501 /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_clinvar_20210501.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_clinvar_20210501.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of gnomad_genome is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_gnomad_genome.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar gnomad_genome /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_gnomad_genome.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_gnomad_genome.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of dbscsnv11 is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_dbscsnv11.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar dbscsnv11 /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_dbscsnv11.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_dbscsnv11.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of rmsk is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_rmsk.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb rmsk /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/rmsk.txt.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of ensGene is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_ensGene.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar ensGene /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_ensGene.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_ensGeneMrna.fa.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: The Annovar dataset file of knownGene is not in /content/annovar/humandb,begin to download this /content/annovar/humandb/hg19_knownGene.txt ...\n",
            "perl /content/annovar/annotate_variation.pl -buildver hg19 -downdb -webfrom annovar knownGene /content/annovar/humandb\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_knownGene.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_kgXref.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg19_knownGeneMrna.fa.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg19 build version, with files saved at the '/content/annovar/humandb' directory\n",
            "Warning: Begin to convert your vcf file of /content/filtered_normal_sample.deepvariant.vcf to AVinput of Annovar ...\n",
            "perl /content/annovar/convert2annovar.pl -format vcf4 /content/filtered_normal_sample.deepvariant.vcf> /content/filtered_normal_sample.deepvariant.vcf.avinput\n",
            "NOTICE: Finished reading 265456 lines from VCF file\n",
            "NOTICE: A total of 262074 locus in VCF file passed QC threshold, representing 223378 SNPs (156231 transitions and 67147 transversions) and 43792 indels/substitutions\n",
            "NOTICE: Finished writing 223351 SNP genotypes (156221 transitions and 67130 transversions) and 42747 indels/substitutions for 1 sample\n",
            "perl /content/annovar/table_annovar.pl /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb -buildver hg19 -remove -out /content/classified_variants -protocol refGene,esp6500siv2_all,1000g2015aug_all,avsnp147,dbnsfp42a,clinvar_20210501,gnomad_genome,dbscsnv11,rmsk,ensGene,knownGene   -operation  g,f,f,f,f,f,f,f,r,g,g   -nastring . --otherinfo \n",
            "NOTICE: the --polish argument is set ON automatically (use --nopolish to change this behavior)\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=g protocol=refGene\n",
            "\n",
            "NOTICE: Running with system command <annotate_variation.pl -geneanno -buildver hg19 -dbtype refGene -outfile /content/classified_variants.refGene -exonsort -nofirstcodondel /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb>\n",
            "NOTICE: Output files are written to /content/classified_variants.refGene.variant_function, /content/classified_variants.refGene.exonic_variant_function\n",
            "NOTICE: Reading gene annotation from /content/annovar/humandb/hg19_refGene.txt ... Done with 78239 transcripts (including 18578 without coding sequence annotation) for 28293 unique genes\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Reading FASTA sequences from /content/annovar/humandb/hg19_refGeneMrna.fa ... Done with 9429 sequences\n",
            "WARNING: A total of 465 sequences will be ignored due to lack of correct ORF annotation\n",
            "\n",
            "---------------------------------------------------------------------------------------\n",
            "WARNING: 3700 exonic SNPs have WRONG reference alleles specified in your input file!\n",
            "WARNING: An example input line is <chr20\t45858481\t45858481\tA\tC\thet\t32.7\t7>\n",
            "WARNING: ANNOVAR can still annotate exonic_variant_function for the mutation correctly!\n",
            "WARNING: you may have used wrong -buildver, or specified incorrect reference allele, or used outdated mRNA FASTA file!\n",
            "---------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "NOTICE: Running with system command <coding_change.pl  /content/classified_variants.refGene.exonic_variant_function.orig /content/annovar/humandb/hg19_refGene.txt /content/annovar/humandb/hg19_refGeneMrna.fa -alltranscript -out /content/classified_variants.refGene.fa -newevf /content/classified_variants.refGene.exonic_variant_function>\n",
            "Warning: 4 transcripts are flagged as having potential ORF issues (premature stopcodon or lack of stop codon)\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=f protocol=esp6500siv2_all\n",
            "\n",
            "NOTICE: Running system command <annotate_variation.pl -filter -dbtype esp6500siv2_all -buildver hg19 -outfile /content/classified_variants /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb>\n",
            "NOTICE: the --dbtype esp6500siv2_all is assumed to be in generic ANNOVAR database format\n",
            "NOTICE: Output file with variants matching filtering criteria is written to /content/classified_variants.hg19_esp6500siv2_all_dropped, and output file with other variants is written to /content/classified_variants.hg19_esp6500siv2_all_filtered\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Database index loaded. Total number of bins is 594771 and the number of bins to be scanned is 9887\n",
            "NOTICE: Scanning filter database /content/annovar/humandb/hg19_esp6500siv2_all.txt...Done\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=f protocol=1000g2015aug_all\n",
            "\n",
            "NOTICE: Running system command <annotate_variation.pl -filter -dbtype 1000g2015aug_all -buildver hg19 -outfile /content/classified_variants /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb>\n",
            "NOTICE: Output file with variants matching filtering criteria is written to /content/classified_variants.hg19_ALL.sites.2015_08_dropped, and output file with other variants is written to /content/classified_variants.hg19_ALL.sites.2015_08_filtered\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Database index loaded. Total number of bins is 2824642 and the number of bins to be scanned is 155882\n",
            "NOTICE: Scanning filter database /content/annovar/humandb/hg19_ALL.sites.2015_08.txt...Done\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=f protocol=avsnp147\n",
            "\n",
            "NOTICE: Running system command <annotate_variation.pl -filter -dbtype avsnp147 -buildver hg19 -outfile /content/classified_variants /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb>\n",
            "NOTICE: Output file with variants matching filtering criteria is written to /content/classified_variants.hg19_avsnp147_dropped, and output file with other variants is written to /content/classified_variants.hg19_avsnp147_filtered\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Database index loaded. Total number of bins is 27868332 and the number of bins to be scanned is 224622\n",
            "NOTICE: Scanning filter database /content/annovar/humandb/hg19_avsnp147.txt...Done\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=f protocol=dbnsfp42a\n",
            "NOTICE: Finished reading 107 column headers for '-dbtype dbnsfp42a'\n",
            "\n",
            "NOTICE: Running system command <annotate_variation.pl -filter -dbtype dbnsfp42a -buildver hg19 -outfile /content/classified_variants /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb -otherinfo>\n",
            "NOTICE: Output file with variants matching filtering criteria is written to /content/classified_variants.hg19_dbnsfp42a_dropped, and output file with other variants is written to /content/classified_variants.hg19_dbnsfp42a_filtered\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Database index loaded. Total number of bins is 553468 and the number of bins to be scanned is 8908\n",
            "NOTICE: Scanning filter database /content/annovar/humandb/hg19_dbnsfp42a.txt...Done\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=f protocol=clinvar_20210501\n",
            "NOTICE: Finished reading 5 column headers for '-dbtype clinvar_20210501'\n",
            "\n",
            "NOTICE: Running system command <annotate_variation.pl -filter -dbtype clinvar_20210501 -buildver hg19 -outfile /content/classified_variants /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb -otherinfo>\n",
            "NOTICE: the --dbtype clinvar_20210501 is assumed to be in generic ANNOVAR database format\n",
            "NOTICE: Output file with variants matching filtering criteria is written to /content/classified_variants.hg19_clinvar_20210501_dropped, and output file with other variants is written to /content/classified_variants.hg19_clinvar_20210501_filtered\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Database index loaded. Total number of bins is 76422 and the number of bins to be scanned is 8009\n",
            "NOTICE: Scanning filter database /content/annovar/humandb/hg19_clinvar_20210501.txt...Done\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=f protocol=gnomad_genome\n",
            "NOTICE: Finished reading 8 column headers for '-dbtype gnomad_genome'\n",
            "\n",
            "NOTICE: Running system command <annotate_variation.pl -filter -dbtype gnomad_genome -buildver hg19 -outfile /content/classified_variants /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb -otherinfo>\n",
            "NOTICE: Output file with variants matching filtering criteria is written to /content/classified_variants.hg19_gnomad_genome_dropped, and output file with other variants is written to /content/classified_variants.hg19_gnomad_genome_filtered\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Database index loaded. Total number of bins is 28127612 and the number of bins to be scanned is 227067\n",
            "NOTICE: Scanning filter database /content/annovar/humandb/hg19_gnomad_genome.txt...Done\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=f protocol=dbscsnv11\n",
            "NOTICE: Finished reading 2 column headers for '-dbtype dbscsnv11'\n",
            "\n",
            "NOTICE: Running system command <annotate_variation.pl -filter -dbtype dbscsnv11 -buildver hg19 -outfile /content/classified_variants /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb -otherinfo>\n",
            "NOTICE: the --dbtype dbscsnv11 is assumed to be in generic ANNOVAR database format\n",
            "NOTICE: Output file with variants matching filtering criteria is written to /content/classified_variants.hg19_dbscsnv11_dropped, and output file with other variants is written to /content/classified_variants.hg19_dbscsnv11_filtered\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Database index loaded. Total number of bins is 421415 and the number of bins to be scanned is 6907\n",
            "NOTICE: Scanning filter database /content/annovar/humandb/hg19_dbscsnv11.txt...Done\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=r protocol=rmsk\n",
            "\n",
            "NOTICE: Running with system command <annotate_variation.pl -regionanno -dbtype rmsk -buildver hg19 -outfile /content/classified_variants /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb>\n",
            "NOTICE: Output file is written to /content/classified_variants.hg19_rmsk\n",
            "NOTICE: Reading annotation database /content/annovar/humandb/hg19_rmsk.txt ... Done with 5481341 regions\n",
            "NOTICE: Finished region-based annotation on 266098 genetic variants\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=g protocol=ensGene\n",
            "\n",
            "NOTICE: Running with system command <annotate_variation.pl -geneanno -buildver hg19 -dbtype ensGene -outfile /content/classified_variants.ensGene -exonsort -nofirstcodondel /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb>\n",
            "NOTICE: Output files are written to /content/classified_variants.ensGene.variant_function, /content/classified_variants.ensGene.exonic_variant_function\n",
            "NOTICE: Reading gene annotation from /content/annovar/humandb/hg19_ensGene.txt ... Done with 103433 transcripts (including 38799 without coding sequence annotation) for 47132 unique genes\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Reading FASTA sequences from /content/annovar/humandb/hg19_ensGeneMrna.fa ... Done with 9727 sequences\n",
            "WARNING: A total of 660 sequences will be ignored due to lack of correct ORF annotation\n",
            "\n",
            "---------------------------------------------------------------------------------------\n",
            "WARNING: 3770 exonic SNPs have WRONG reference alleles specified in your input file!\n",
            "WARNING: An example input line is <chr4\t25125687\t25125687\tT\tC\thet\t32.6\t202>\n",
            "WARNING: ANNOVAR can still annotate exonic_variant_function for the mutation correctly!\n",
            "WARNING: you may have used wrong -buildver, or specified incorrect reference allele, or used outdated mRNA FASTA file!\n",
            "---------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "NOTICE: Running with system command <coding_change.pl  /content/classified_variants.ensGene.exonic_variant_function.orig /content/annovar/humandb/hg19_ensGene.txt /content/annovar/humandb/hg19_ensGeneMrna.fa -alltranscript -out /content/classified_variants.ensGene.fa -newevf /content/classified_variants.ensGene.exonic_variant_function>\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=g protocol=knownGene\n",
            "\n",
            "NOTICE: Running with system command <annotate_variation.pl -geneanno -buildver hg19 -dbtype knownGene -outfile /content/classified_variants.knownGene -exonsort -nofirstcodondel /content/filtered_normal_sample.deepvariant.vcf.avinput /content/annovar/humandb>\n",
            "NOTICE: Output files are written to /content/classified_variants.knownGene.variant_function, /content/classified_variants.knownGene.exonic_variant_function\n",
            "NOTICE: Reading gene annotation from /content/annovar/humandb/hg19_knownGene.txt ... Done with 78963 transcripts (including 18502 without coding sequence annotation) for 28495 unique genes\n",
            "NOTICE: Processing next batch with 266098 unique variants in 266098 input lines\n",
            "NOTICE: Reading FASTA sequences from /content/annovar/humandb/hg19_knownGeneMrna.fa ... Done with 9077 sequences\n",
            "WARNING: A total of 43 sequences will be ignored due to lack of correct ORF annotation\n",
            "\n",
            "---------------------------------------------------------------------------------------\n",
            "WARNING: 3886 exonic SNPs have WRONG reference alleles specified in your input file!\n",
            "WARNING: An example input line is <chr21\t27056256\t27056256\tT\tC\thom\t35.6\t3>\n",
            "WARNING: ANNOVAR can still annotate exonic_variant_function for the mutation correctly!\n",
            "WARNING: you may have used wrong -buildver, or specified incorrect reference allele, or used outdated mRNA FASTA file!\n",
            "---------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "NOTICE: Running with system command <coding_change.pl  /content/classified_variants.knownGene.exonic_variant_function.orig /content/annovar/humandb/hg19_knownGene.txt /content/annovar/humandb/hg19_knownGeneMrna.fa -alltranscript -out /content/classified_variants.knownGene.fa -newevf /content/classified_variants.knownGene.exonic_variant_function>\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Multianno output file is written to /content/classified_variants.hg19_multianno.txt\n",
            "Warning: Customized  disease cutoff 0.01 in config.ini, not suggested as 0.005\n",
            "Notice: Begin the variants interpretation by InterVar \n",
            "Notice: About 266098 lines in your variant file! \n",
            "Notice: About 379333 variants has been processed by InterVar\n",
            "Notice: The InterVar is finished, the output file is [ /content/classified_variants.hg19_multianno.txt.intervar ]\n",
            "=============================================================================\n",
            "........................................................................\n",
            ".####.##....##.########.########.########..##.....##....###....########.\n",
            "..##..###...##....##....##.......##.....##.##.....##...##.##...##.....##\n",
            "..##..####..##....##....##.......##.....##.##.....##..##...##..##.....##\n",
            "..##..##.##.##....##....######...########..##.....##.##.....##.########.\n",
            "..##..##..####....##....##.......##...##....##...##..#########.##...##..\n",
            "..##..##...###....##....##.......##....##....##.##...##.....##.##....##.\n",
            ".####.##....##....##....########.##.....##....###....##.....##.##.....##\n",
            ".......................................................................\n",
            "Thanks for using InterVar!\n",
            "Report bugs to leequan@gmail.com;\n",
            "InterVar homepage: <http://wInterVar.wglab.org>\n",
            "\n",
            "=============================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Install required libraries/packages for report generation**"
      ],
      "metadata": {
        "id": "U0x1amPT_P2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "magnwIiVHYwc",
        "outputId": "f70cb51b-09cf-4ff0-ff0b-07b362ee4fd2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n",
            "Installing collected packages: reportlab\n",
            "Successfully installed reportlab-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib import colors\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.units import inch"
      ],
      "metadata": {
        "id": "StMUgIb1Kt_b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kigMXevoIF3v"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "R5XtsSKtXTMd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vcf"
      ],
      "metadata": {
        "id": "mRJTRud1eR1V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9: Parse VCF and Intervar files while extracting and storing relevant information in the form of dataframe.**"
      ],
      "metadata": {
        "id": "eDIzQxmC_d9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing VCF and Intervar dataframes with relevant information from each file for the report\n",
        "\n",
        "def parse_vcf(vcf_path):\n",
        "    vcf_data = []\n",
        "    vcf_in = pysam.VariantFile(vcf_path, 'r')\n",
        "    for record in vcf_in.fetch():\n",
        "        qual = round(record.qual,2) if record.qual else 0\n",
        "        filter_status = ';'.join(list(record.filter.keys())) if record.filter else 'PASS'\n",
        "        vcf_data.append([record.chrom, str(record.pos), record.ref, ','.join(record.alts), qual, filter_status])\n",
        "    return pd.DataFrame(vcf_data, columns=['Chromosome', 'Position', 'Reference Allele', 'Alternate Allele', 'Variant Quality', 'Filter Status'])\n",
        "\n",
        "\n",
        "def extract_acmg_classification(evidence_string):\n",
        "    known_classifications = ['Benign', 'Pathogenic', 'Likely benign', 'Likely pathogenic', 'Uncertain significance']\n",
        "\n",
        "    parts = evidence_string.split(';')\n",
        "    intervar_part = parts[0] if parts else \"\"\n",
        "    words = intervar_part.split()\n",
        "    classification = \" \".join(words[1:3]) if len(words) > 1 else \"Unknown\"\n",
        "\n",
        "    for known_class in known_classifications:\n",
        "        if classification.startswith(known_class):\n",
        "            return known_class\n",
        "\n",
        "    return classification\n",
        "\n",
        "def parse_intervar(intervar_path):\n",
        "    intervar_data = []\n",
        "    with open(intervar_path, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('#'): continue  # to skip header lines\n",
        "            parts = line.strip().split('\\t')\n",
        "            chr, start = parts[0], parts[1]\n",
        "            intervar_evidence = parts[13]\n",
        "            acmg_classification = extract_acmg_classification(intervar_evidence)\n",
        "            intervar_data.append([chr, start, acmg_classification])\n",
        "\n",
        "    return pd.DataFrame(intervar_data, columns=['Chromosome', 'Position', 'ACMG Classification'])\n",
        "\n",
        "vcf_df = parse_vcf('/content/filtered_normal_sample.deepvariant.vcf')\n",
        "intervar_df = parse_intervar('/content/classified_variants.hg19_multianno.txt.intervar')\n",
        "intervar_df['Chromosome'] = intervar_df['Chromosome'].apply(lambda x: 'chr' + x if not x.startswith('chr') else x) #because Intervar file had different type (integers only) of entries in chromosome column\n"
      ],
      "metadata": {
        "id": "fVsgXkRfKqFj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just to check if everything is in place for report generation\n",
        "vcf_df_subset = vcf_df.iloc[:50]\n",
        "intervar_df_subset = intervar_df.iloc[:50]\n",
        "\n",
        "merged_subset = pd.merge(vcf_df_subset, intervar_df_subset, on=[\"Chromosome\", \"Position\"], how='inner')\n",
        "\n",
        "print(merged_subset.head(50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOIy_NX8Vubi",
        "outputId": "44a06f2a-f209-44d4-ff0e-920a5cd3b0bf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Chromosome Position Reference Allele  \\\n",
            "0        chr1    15820                G   \n",
            "1        chr1    15903                G   \n",
            "2        chr1    69270                A   \n",
            "3        chr1    69511                A   \n",
            "4        chr1    69897                T   \n",
            "5        chr1   187302                A   \n",
            "6        chr1   187302                A   \n",
            "7        chr1   872909                A   \n",
            "8        chr1   873542                G   \n",
            "9        chr1   890174                A   \n",
            "10       chr1   914618                A   \n",
            "11       chr1   914991                G   \n",
            "12       chr1   930939                G   \n",
            "13       chr1   930939                G   \n",
            "14       chr1   931540                A   \n",
            "15       chr1   931540                A   \n",
            "16       chr1   931558                G   \n",
            "17       chr1   931558                G   \n",
            "18       chr1   935386                C   \n",
            "19       chr1   935523                T   \n",
            "20       chr1   938654                G   \n",
            "21       chr1   938654                G   \n",
            "22       chr1   939570                T   \n",
            "23       chr1   939570                T   \n",
            "24       chr1   941119                A   \n",
            "25       chr1   941119                A   \n",
            "26       chr1   942335                C   \n",
            "27       chr1   942335                C   \n",
            "28       chr1   942451                T   \n",
            "29       chr1   942451                T   \n",
            "30       chr1   944296                G   \n",
            "31       chr1   944296                G   \n",
            "32       chr1   944307                T   \n",
            "33       chr1   944307                T   \n",
            "34       chr1   944858                A   \n",
            "35       chr1   944858                A   \n",
            "36       chr1   946247                G   \n",
            "37       chr1   946247                G   \n",
            "38       chr1   948245                A   \n",
            "39       chr1   948711                C   \n",
            "40       chr1   949046                A   \n",
            "41       chr1   950626                T   \n",
            "\n",
            "                              Alternate Allele  Variant Quality Filter Status  \\\n",
            "0                                            T             22.2          PASS   \n",
            "1                                           GC             28.9          PASS   \n",
            "2                                            G             27.0          PASS   \n",
            "3                                            G             23.2          PASS   \n",
            "4                                            C             21.2          PASS   \n",
            "5                                            G             20.8          PASS   \n",
            "6                                            G             20.8          PASS   \n",
            "7                                            T             26.1          PASS   \n",
            "8                                            A             66.9          PASS   \n",
            "9                                            G             30.3          PASS   \n",
            "10                                           G             34.2          PASS   \n",
            "11                                           T             20.9          PASS   \n",
            "12                                           A             65.8          PASS   \n",
            "13                                           A             65.8          PASS   \n",
            "14                                           G             40.8          PASS   \n",
            "15                                           G             40.8          PASS   \n",
            "16                                           A             39.3          PASS   \n",
            "17                                           A             39.3          PASS   \n",
            "18                                           T             41.7          PASS   \n",
            "19                                           C             60.0          PASS   \n",
            "20                                           A             40.4          PASS   \n",
            "21                                           A             40.4          PASS   \n",
            "22                               TCCCTGGAGGACC             40.1          PASS   \n",
            "23                               TCCCTGGAGGACC             40.1          PASS   \n",
            "24                                           G             58.2          PASS   \n",
            "25                                           G             58.2          PASS   \n",
            "26                                           G             65.1          PASS   \n",
            "27                                           G             65.1          PASS   \n",
            "28                                           C             62.3          PASS   \n",
            "29                                           C             62.3          PASS   \n",
            "30                                           A             59.3          PASS   \n",
            "31                                           A             59.3          PASS   \n",
            "32                                           C             57.1          PASS   \n",
            "33                                           C             57.1          PASS   \n",
            "34                                           G             61.4          PASS   \n",
            "35                                           G             61.4          PASS   \n",
            "36                                           A             56.4          PASS   \n",
            "37                                           A             56.4          PASS   \n",
            "38                                           G             47.9          PASS   \n",
            "39  CACCCTGGTCCCCCTGGTCCCTTTGGCCCTGCACCTGGCTGG             33.3          PASS   \n",
            "40                                  AACAGCAAAG             25.8          PASS   \n",
            "41                                           C             46.2          PASS   \n",
            "\n",
            "       ACMG Classification  \n",
            "0                   Benign  \n",
            "1                   Benign  \n",
            "2                   Benign  \n",
            "3                   Benign  \n",
            "4                   Benign  \n",
            "5   Uncertain significance  \n",
            "6   Uncertain significance  \n",
            "7   Uncertain significance  \n",
            "8   Uncertain significance  \n",
            "9   Uncertain significance  \n",
            "10  Uncertain significance  \n",
            "11           Likely benign  \n",
            "12  Uncertain significance  \n",
            "13  Uncertain significance  \n",
            "14  Uncertain significance  \n",
            "15  Uncertain significance  \n",
            "16  Uncertain significance  \n",
            "17  Uncertain significance  \n",
            "18  Uncertain significance  \n",
            "19  Uncertain significance  \n",
            "20  Uncertain significance  \n",
            "21  Uncertain significance  \n",
            "22  Uncertain significance  \n",
            "23  Uncertain significance  \n",
            "24  Uncertain significance  \n",
            "25  Uncertain significance  \n",
            "26  Uncertain significance  \n",
            "27  Uncertain significance  \n",
            "28  Uncertain significance  \n",
            "29  Uncertain significance  \n",
            "30  Uncertain significance  \n",
            "31  Uncertain significance  \n",
            "32  Uncertain significance  \n",
            "33  Uncertain significance  \n",
            "34  Uncertain significance  \n",
            "35  Uncertain significance  \n",
            "36  Uncertain significance  \n",
            "37  Uncertain significance  \n",
            "38  Uncertain significance  \n",
            "39  Uncertain significance  \n",
            "40  Uncertain significance  \n",
            "41  Uncertain significance  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10: Generate PDF report and download it.**"
      ],
      "metadata": {
        "id": "WLwiF3p0ALH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the sample ID and gender information from the VCF file\n",
        "vcf_path = '/content/filtered_normal_sample.deepvariant.vcf'  # make sure to use filtered vcf\n",
        "vcf_reader = vcf.Reader(open(vcf_path, 'r'))\n",
        "sample_id = vcf_reader.samples[0] if vcf_reader.samples else \"Unknown\"\n",
        "\n",
        "gender = \"Female\"\n",
        "for record in vcf_reader:\n",
        "    if record.CHROM == \"Y\" or record.CHROM == \"chrY\":\n",
        "        gender = \"Male\"\n",
        "        break\n",
        "\n",
        "patient_details = {\n",
        "    \"Patient ID\": sample_id,\n",
        "    \"Date of Birth\": \"1994-03-20\",\n",
        "    \"Gender\": gender,\n",
        "    \"Ethnicity\": \"Asian\",\n",
        "    \"Family History\": \"None\"\n",
        "}\n",
        "\n",
        "#Creating function to wrap text for entries in allele columns that have multiple nucleotides to adjust the table on the page\n",
        "def wrap_text(text, max_length=9):\n",
        "    wrapped_text = '\\n'.join([text[i:i+max_length] for i in range(0, len(text), max_length)])\n",
        "    return wrapped_text\n",
        "\n",
        "# Function to generate PDF including patient details\n",
        "def generate_pdf(data, filename, patient_info):\n",
        "    pdf = SimpleDocTemplate(filename, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elems = []\n",
        "\n",
        "    for key, value in patient_info.items():\n",
        "        elems.append(Paragraph(f'<b>{key}:</b> {value}', styles['Normal']))\n",
        "        elems.append(Spacer(1, 12))\n",
        "\n",
        "    elems.append(Spacer(1, 20))\n",
        "\n",
        "    # Preparing data with wrapped text for alleles\n",
        "    wrapped_data = []\n",
        "    for row in data:\n",
        "        wrapped_row = [\n",
        "            row[0],\n",
        "            row[1],\n",
        "            wrap_text(row[2]), #Wrapping reference allele column\n",
        "            wrap_text(row[3]), #Wrapping alternate allele column\n",
        "            row[4],\n",
        "            row[5],\n",
        "            row[6]\n",
        "        ]\n",
        "        wrapped_data.append(wrapped_row)\n",
        "\n",
        "    variant_table = Table(wrapped_data)\n",
        "    variant_table.setStyle(TableStyle([\n",
        "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
        "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
        "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
        "        ('GRID', (0,0), (-1,-1), 1, colors.black),\n",
        "        ('VALIGN', (0,0), (-1,-1), 'TOP'),\n",
        "    ]))\n",
        "\n",
        "    elems.append(variant_table)\n",
        "    pdf.build(elems)\n",
        "\n",
        "#Checking with subset of data if the PDF being built is in correct format\n",
        "data_for_pdf = [[\"Chromosome\", \"Position\", \"Reference Allele\", \"Alternate Allele\", \"Variant Quality\", \"Filter Status\", \"ACMG Classification\"]] + merged_subset.values.tolist()\n",
        "\n",
        "pdf_report_path = '/content/variant_report_with_patient_details.pdf'\n",
        "\n",
        "generate_pdf(data_for_pdf, pdf_report_path, patient_details)\n",
        "\n",
        "print(\"PDF report generated:\", pdf_report_path)\n",
        "\n",
        "#For downloading the PDF file as soon as the file is generated\n",
        "from google.colab import files\n",
        "files.download(pdf_report_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "71RCBpFRaunx",
        "outputId": "a3fdde76-982e-4d13-99a9-edf497dc17f8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF report generated: /content/variant_report_with_patient_details.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3fb7fbed-b5c4-4fa9-adbc-6745ac4934ca\", \"variant_report_with_patient_details.pdf\", 4917)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.merge(vcf_df, intervar_df, on=[\"Chromosome\", \"Position\"], how='inner')\n",
        "\n",
        "full_data_for_pdf = [[\"Chromosome\", \"Position\", \"Reference Allele\", \"Alternate Allele\", \"Variant Quality\", \"Filter Status\", \"ACMG Classification\"]] + combined_df.values.tolist()\n",
        "\n",
        "pdf_report_path = '/content/full_variant_report_with_patient_details.pdf'\n",
        "\n",
        "generate_pdf(full_data_for_pdf, pdf_report_path, patient_details)\n",
        "\n",
        "print(\"PDF report generated:\", pdf_report_path)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(pdf_report_path)"
      ],
      "metadata": {
        "id": "exsZJ7e0eofZ",
        "outputId": "38306023-bb15-4443-f71d-b1f203389c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF report generated: /content/full_variant_report_with_patient_details.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b79d6deb-ff89-4e62-aef7-47ac1ef3b244\", \"full_variant_report_with_patient_details.pdf\", 22777879)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
